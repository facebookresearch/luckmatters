[2024-04-06 03:17:04,506][decoder_only.py][INFO] - 
===*** Job start ***===
Command line:
    
decoder_only.py \
  d=128 \
  L=128 \
  H=1 \
  niter=100 \
  save_per_minibatch=2 \
  opt.wd=0 \
  batchsize=128 \
  seed=2 \
  model2.normalize=true \
  opt.method=sgd \
  model2.residual=false \
  dataset2.num_last=2 \
  dataset2.num_next_per_last=1 \
  dataset2.num_common_per_last=0 \
  opt.lr_z=1 \
  opt.lr_y_multi_on_z=1 \

    
Working dir: /private/home/yuandong/luckmatters/ssl/real-dataset/outputs/2024-04-06/03-17-04
e908073679b62563d4baaf710d5d97824987a519
diff --git a/ssl/real-dataset/README.md b/ssl/real-dataset/README.md
index f56b86f..0bb992a 100644
--- a/ssl/real-dataset/README.md
+++ b/ssl/real-dataset/README.md
@@ -150,7 +150,7 @@ To reproduce Fig. 8, you can run `joma/draw_figure_8.py`. The sweep run paramete
 
 To train a model on synthetic data generated by a hierarchical model, and verify the correlation between the latents and the neuron activations (Table 1 in the paper), please use:
 ```
-python decoder_only_hier.py niter=10000 save_per_minibatch=2000 opt.method=adam opt.lr=1e-4 opt.wd=0.001 seed=1 num_class=20 M=100 L=30 model.nlayer=3 gen.num_tokens=[20,30,null] gen.num_combinations=[3,3,3] model.d=2048
+python decoder_only_hier.py opt.method=adam niter=10000 save_per_minibatch=5000 opt.lr=1e-5 opt.wd=0.0001 seed=1 num_class=20 M=100 L=30 model.nlayer=3 gen.num_tokens=[10,20,null] gen.num_combinations=[2,2,2] model.d=1024 +model.hidden_multi_type=M +model.hidden_multi=4
 ```
 
 # Reference
diff --git a/ssl/real-dataset/decoder_only_hier.py b/ssl/real-dataset/decoder_only_hier.py
index 110bda9..79739d8 100644
--- a/ssl/real-dataset/decoder_only_hier.py
+++ b/ssl/real-dataset/decoder_only_hier.py
@@ -114,6 +114,8 @@ class Model(nn.Module):
         else:
             raise RuntimeError(f"Unknown hidden_multi_type {hidden_multi_type}")
 
+        log.info(f"d_hidden: {d_hidden}")
+
         self.embed = nn.Embedding(M, d) # max_norm=1)
 
         # orthogonal_frozen_embed=False, 
@@ -392,4 +394,4 @@ def main(args):
     log.info(os.getcwd())
 
 if __name__ == '__main__':
-    main()
\ No newline at end of file
+    main()


niter: 100
seed: 2
L: 128
M: 24
d: 128
H: 1
dataset2:
  num_last: 2
  num_next_per_last: 1
  num_common: 10
  num_common_per_last: 0
  num_unique_per_next: 10
  common_unnormalized_prob: 1
  unique_unnormalized_min: 0.1
  unique_unnormalized_max: 1
dataset:
  num_groups: 5
  num_facts_per_group: 4
batchsize: 128
save_per_minibatch: 2
model:
  nlayer: 1
  use_Wk: true
  use_Wq: true
  use_Wv: true
  use_ffn: false
  use_residue: true
  use_ln: false
  gate: relu
  universal_Wv: false
  universal_WkWq: false
  normalize_embed_shift: false
  normalize_embed_scale: none
  use_random_grad: false
model2:
  attn_include_base_token: false
  zero_init: true
  normalize: true
  residual: false
opt:
  method: sgd
  lr: 0.1
  lr_y: none,
  lr_y_multi_on_z: 1
  lr_z: 1
  momentum: 0.9
  wd: 0


[2024-04-06 03:17:04,531][decoder_only.py][INFO] - Generated 2 facts: 
[2024-04-06 03:17:04,531][decoder_only.py][INFO] - [{'probs': tensor([0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645,
        0.0645, 0.0065, 0.0129, 0.0194, 0.0258, 0.0323, 0.0387, 0.0452, 0.0516,
        0.0581, 0.0645]), 'tokens': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19]), 'common_per_last_range': (10, 10), 'unique_range': (10, 20), 'last_token': 30, 'next_token': 32}, {'probs': tensor([0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645,
        0.0645, 0.0065, 0.0129, 0.0194, 0.0258, 0.0323, 0.0387, 0.0452, 0.0516,
        0.0581, 0.0645]), 'tokens': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 20, 21, 22, 23, 24, 25, 26, 27,
        28, 29]), 'common_per_last_range': (10, 10), 'unique_range': (20, 30), 'last_token': 31, 'next_token': 33}]
[2024-04-06 03:17:05,789][decoder_only.py][INFO] - lr y = 1, lr z = 1
[2024-04-06 03:17:06,124][decoder_only.py][INFO] - [0] loss: 3.526359796524048
[2024-04-06 03:17:06,142][decoder_only.py][INFO] - [2] loss: 2.3679099082946777
[2024-04-06 03:17:06,159][decoder_only.py][INFO] - [4] loss: 0.733475387096405
[2024-04-06 03:17:06,175][decoder_only.py][INFO] - [6] loss: 0.16080491244792938
[2024-04-06 03:17:06,192][decoder_only.py][INFO] - [8] loss: 0.04442878067493439
[2024-04-06 03:17:06,209][decoder_only.py][INFO] - [10] loss: 0.012952473945915699
[2024-04-06 03:17:06,225][decoder_only.py][INFO] - [12] loss: 0.004386259242892265
[2024-04-06 03:17:06,242][decoder_only.py][INFO] - [14] loss: 0.0018097831634804606
[2024-04-06 03:17:06,259][decoder_only.py][INFO] - [16] loss: 0.0006407027249224484
[2024-04-06 03:17:06,276][decoder_only.py][INFO] - [18] loss: 0.0004101922386325896
[2024-04-06 03:17:06,293][decoder_only.py][INFO] - [20] loss: 0.00020543375285342336
[2024-04-06 03:17:06,310][decoder_only.py][INFO] - [22] loss: 0.0001480427454225719
[2024-04-06 03:17:06,326][decoder_only.py][INFO] - [24] loss: 0.0001294454123126343
[2024-04-06 03:17:06,343][decoder_only.py][INFO] - [26] loss: 8.063780114753172e-05
[2024-04-06 03:17:06,359][decoder_only.py][INFO] - [28] loss: 6.175993621582165e-05
[2024-04-06 03:17:06,377][decoder_only.py][INFO] - [30] loss: 5.301201599650085e-05
[2024-04-06 03:17:06,393][decoder_only.py][INFO] - [32] loss: 5.059645991423167e-05
[2024-04-06 03:17:06,409][decoder_only.py][INFO] - [34] loss: 3.5792043490801007e-05
[2024-04-06 03:17:06,426][decoder_only.py][INFO] - [36] loss: 3.449523865128867e-05
[2024-04-06 03:17:06,443][decoder_only.py][INFO] - [38] loss: 3.0941479053581133e-05
[2024-04-06 03:17:06,459][decoder_only.py][INFO] - [40] loss: 2.911147748818621e-05
[2024-04-06 03:17:06,476][decoder_only.py][INFO] - [42] loss: 2.9778911994071677e-05
[2024-04-06 03:17:06,492][decoder_only.py][INFO] - [44] loss: 3.086395372520201e-05
[2024-04-06 03:17:06,509][decoder_only.py][INFO] - [46] loss: 2.48462674790062e-05
[2024-04-06 03:17:06,525][decoder_only.py][INFO] - [48] loss: 2.5099543563555926e-05
[2024-04-06 03:17:06,543][decoder_only.py][INFO] - [50] loss: 2.5783052478800528e-05
[2024-04-06 03:17:06,559][decoder_only.py][INFO] - [52] loss: 2.6792611606651917e-05
[2024-04-06 03:17:06,576][decoder_only.py][INFO] - [54] loss: 2.2869091480970383e-05
[2024-04-06 03:17:06,592][decoder_only.py][INFO] - [56] loss: 2.1117355572641827e-05
[2024-04-06 03:17:06,608][decoder_only.py][INFO] - [58] loss: 2.5497896785964258e-05
[2024-04-06 03:17:06,625][decoder_only.py][INFO] - [60] loss: 2.4302386009367183e-05
[2024-04-06 03:17:06,641][decoder_only.py][INFO] - [62] loss: 2.2612024622503668e-05
[2024-04-06 03:17:06,658][decoder_only.py][INFO] - [64] loss: 2.6725640054792166e-05
[2024-04-06 03:17:06,675][decoder_only.py][INFO] - [66] loss: 2.238919296360109e-05
[2024-04-06 03:17:06,691][decoder_only.py][INFO] - [68] loss: 2.2064519725972787e-05
[2024-04-06 03:17:06,708][decoder_only.py][INFO] - [70] loss: 1.994945887417998e-05
[2024-04-06 03:17:06,725][decoder_only.py][INFO] - [72] loss: 2.241275433334522e-05
[2024-04-06 03:17:06,741][decoder_only.py][INFO] - [74] loss: 2.1630286937579513e-05
[2024-04-06 03:17:06,758][decoder_only.py][INFO] - [76] loss: 1.95900665858062e-05
[2024-04-06 03:17:06,774][decoder_only.py][INFO] - [78] loss: 2.687439337023534e-05
[2024-04-06 03:17:06,791][decoder_only.py][INFO] - [80] loss: 2.182226671720855e-05
[2024-04-06 03:17:06,808][decoder_only.py][INFO] - [82] loss: 2.19909634324722e-05
[2024-04-06 03:17:06,825][decoder_only.py][INFO] - [84] loss: 2.0960904294042848e-05
[2024-04-06 03:17:06,841][decoder_only.py][INFO] - [86] loss: 2.1617408492602408e-05
[2024-04-06 03:17:06,858][decoder_only.py][INFO] - [88] loss: 1.9687886378960684e-05
[2024-04-06 03:17:06,875][decoder_only.py][INFO] - [90] loss: 2.2005695427651517e-05
[2024-04-06 03:17:06,892][decoder_only.py][INFO] - [92] loss: 2.6310464818379842e-05
[2024-04-06 03:17:06,908][decoder_only.py][INFO] - [94] loss: 2.365312866459135e-05
[2024-04-06 03:17:06,925][decoder_only.py][INFO] - [96] loss: 2.237727676401846e-05
[2024-04-06 03:17:06,941][decoder_only.py][INFO] - [98] loss: 2.2223721316549927e-05
[2024-04-06 03:17:06,952][decoder_only.py][INFO] - /private/home/yuandong/luckmatters/ssl/real-dataset/outputs/2024-04-06/03-17-04
